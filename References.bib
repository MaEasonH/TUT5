@article{Nonresponse_Rates,
    author = {Groves, Robert M. and Peytcheva, Emilia},
    title = "{The Impact of Nonresponse Rates on Nonresponse Bias: A Meta-Analysis}",
    journal = {Public Opinion Quarterly},
    volume = {72},
    number = {2},
    pages = {167-189},
    year = {2008},
    month = {05},
    abstract = "{Fifty-nine methodological studies were designed to estimate the magnitude of nonresponse bias in statistics of interest. These studies use a variety of designs: sampling frames with rich variables, data from administrative records matched to sample case, use of screening-interview data to describe nonrespondents to main interviews, followup of nonrespondents to initial phases of field effort, and measures of behavior intentions to respond to a survey. This permits exploration of which circumstances produce a relationship between nonresponse rates and nonresponse bias and which, do not. The predictors are design features of the surveys, characteristics of the sample, and attributes of the survey statistics computed in the surveys.}",
    issn = {0033-362X},
    doi = {10.1093/poq/nfn011},
    url = {https://doi.org/10.1093/poq/nfn011},
    eprint = {https://academic.oup.com/poq/article-pdf/72/2/167/5415366/nfn011.pdf},
}


@article{Accuracy,
    author = {S訏rndal, Carl-Erik and Lundquist, Peter},
    title = "{Accuracy in Estimation with Nonresponse: A Function of Degree of Imbalance and Degree of Explanation}",
    journal = {Journal of Survey Statistics and Methodology},
    volume = {2},
    number = {4},
    pages = {361-387},
    year = {2014},
    month = {09},
    abstract = "{Responsive Design is a trend in recent survey literature concerned notably with managing data collection, through planning and appropriate intervention, so as to realize a well-balanced final set of respondents. In this effort, auxiliary variables, including paradata, are central. But regardless of what is done in the data collection, accurate estimation despite nonresponse is the ultimate goal. The auxiliary variables are important at the estimation stage as well, as when calibrated weights are used in the nonresponse adjustment. For accuracy, two factors intervene: (1) in the data collection, the level of imbalance achieved with the auxiliary information; and (2) in the estimation, the degree to which the auxiliaries explain the study variable. In practice, both objectives are less than completely satisfied. Reduced imbalance in data collection does not by itself guarantee low bias in the estimates. We ask: Is balancing worth a perhaps costly and demanding effort in data collection? Could one have done equally well by saving the use of the auxiliary information until the estimation stage? Complete bias elimination is not achieved at either stage. We outline a theory for a two-factor explanation of accuracy, and apply it to two important surveys at Statistics Sweden. The factors鈥攖he degree of imbalance and the degree of explanation鈥攁re systematically varied, and their joint effect on the accuracy of the estimates is evaluated empirically. The results show that reduced imbalance makes the adjustment of the simple estimate lose some of its importance. More importantly, the calibration-adjusted estimate realizes some accuracy improvement by having been preceded in data collection by a reduced imbalance. The explanation of why this happens is not simple, but a theoretical justification is outlined.}",
    issn = {2325-0984},
    doi = {10.1093/jssam/smu014},
    url = {https://doi.org/10.1093/jssam/smu014},
    eprint = {https://academic.oup.com/jssam/article-pdf/2/4/361/9666216/smu014.pdf},
}


@article{Trends,
    author = {Williams, Douglas and Brick, J Michael},
    title = "{Trends in U.S. Face-To-Face Household Survey Nonresponse and Level of Effort}",
    journal = {Journal of Survey Statistics and Methodology},
    volume = {6},
    number = {2},
    pages = {186-211},
    year = {2017},
    month = {07},
    abstract = "{Research on nonresponse in face-to-face surveys in the United States has shown that nonresponse increases over time for most surveys, but there are also periods of fairly stable rates. Surprisingly, nonresponse for face-to-face surveys has not been as widely studied recently as compared to telephone surveys. The focus on telephone surveys may be due to the dramatic increase in nonresponse for these surveys or perhaps because face-to-face surveys still achieve relatively high levels of response. This paper updates nonresponse trends for face-to-face household surveys conducted in the United States since 2000. The review provides a comprehensive picture of the industry by including surveys conducted by government, private, and academic organizations. The relative role of refusals and noncontacts in the total nonresponse is also presented. We tie the trends in nonresponse with data on the level of effort for some of these surveys. Many researchers have suggested that extra effort has been needed to prevent response rates from falling even more precipitously but lacked the effort data to evaluate this hypothesis for face-to-face surveys. Some data on field effort are becoming available, so this question can be addressed for the first time across more than one survey. To complete the picture, we also look at loss over time for longitudinal face-to-face surveys.}",
    issn = {2325-0984},
    doi = {10.1093/jssam/smx019},
    url = {https://doi.org/10.1093/jssam/smx019},
    eprint = {https://academic.oup.com/jssam/article-pdf/6/2/186/24807380/smx019.pdf},
}

@article{Level-of-Effort,
    author = {Wagner, James and Valliant, Richard and Hubbard, Frost and Jiang, Li (Charley)},
    title = "{Level-of-Effort Paradata and Nonresponse Adjustment Models for a National Face-to-Face Survey}",
    journal = {Journal of Survey Statistics and Methodology},
    volume = {2},
    number = {4},
    pages = {410-432},
    year = {2014},
    month = {08},
    abstract = "{Level-of-effort paradata include information such as the number and timing of attempts and whether there was ever resistance on a sampled case. These types of data are very useful for predicting the probability of response. However, in order to be useful for nonresponse adjustment purposes, data from the sampling frame and paradata need to predict response and the survey variables of interest. Whether level-of-effort paradata will predict survey variables is an empirical question for any specific survey. We examine the utility of these data for nonresponse adjustment purposes in a large, national survey of health and financial measures. Through a series of models and comparisons of alternative weights, we conclude that although the level-of-effort paradata are very useful for predicting the probability of response, for this survey they are not predictive of key survey outcomes and are, therefore, excluded from the adjustment models.}",
    issn = {2325-0984},
    doi = {10.1093/jssam/smu012},
    url = {https://doi.org/10.1093/jssam/smu012},
    eprint = {https://academic.oup.com/jssam/article-pdf/2/4/410/9666202/smu012.pdf},
}
